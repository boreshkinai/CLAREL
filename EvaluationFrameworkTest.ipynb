{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'PATH': '/opt/conda/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
       "        'HOSTNAME': '78353253e378',\n",
       "        'TERM': 'xterm-color',\n",
       "        'NVIDIA_VISIBLE_DEVICES': '1',\n",
       "        'CUDA_VERSION': '9.0.176',\n",
       "        'CUDA_PKG_VERSION': '9-0=9.0.176-1',\n",
       "        'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\n",
       "        'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility',\n",
       "        'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0',\n",
       "        'NCCL_VERSION': '2.4.2',\n",
       "        'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\n",
       "        'CUDNN_VERSION': '7.4.2.24',\n",
       "        'LANG': 'C.UTF-8',\n",
       "        'HOME': '/root',\n",
       "        'JPY_PARENT_PID': '6',\n",
       "        'CLICOLOR': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       "        'CUDA_VISIBLE_DEVICES': '1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['NVIDIA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from train import ModelLoader, load_and_save_params, MetricLoader\n",
    "from datasets.cvpr2016_cub_loader import Cvpr2016CubLoader\n",
    "from common.util import Namespace\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree, KDTree\n",
    "import time\n",
    "from common.metrics import ap_at_k_prototypes\n",
    "import os, pwd\n",
    "from common.pretrained_models import InceptionV3Loader, InceptionV2Loader\n",
    "from common.pretrained_models import INCEPTION_V2_PATH\n",
    "from PIL import Image\n",
    "from datasets.dataset_list import get_dataset_splits\n",
    "from common.metrics import get_prototypes, top1_gzsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test nearest neighbour model loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Searching for '/mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/params.json'\n",
      "INFO:root:Loading existing params.\n",
      "INFO:root:Searching for '/mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/params.json'\n",
      "INFO:root:Loading existing params.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/train/model-150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/train/model-150000\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE'\n",
    "# model_dir = 'mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2018_flowers;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE'\n",
    "\n",
    "log_dir = f\"/mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/{model_dir}\"\n",
    "\n",
    "\n",
    "metric_model = MetricLoader(model_path=log_dir, batch_size_image=100, batch_size_text=200)\n",
    "\n",
    "feature_model = ModelLoader(model_path=log_dir, batch_size=None,\n",
    "                            num_images=metric_model.flags.num_images, num_texts=metric_model.flags.num_texts, \n",
    "                            max_text_len=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading split trainval\n",
      "INFO:root:Loading cached file /mnt/datasets/public/research/cvpr2016_cub/split_trainval_xian2017.pkl\n",
      "INFO:root:Loaded cache in 8.074689 sec\n",
      "INFO:root:Loading split test_seen\n",
      "INFO:root:Loading cached file /mnt/datasets/public/research/cvpr2016_cub/split_test_seen_xian2017.pkl\n",
      "INFO:root:Loaded cache in 2.866140 sec\n",
      "INFO:root:Loading split test_unseen\n",
      "INFO:root:Loading cached file /mnt/datasets/public/research/cvpr2016_cub/split_test_unseen_xian2017.pkl\n",
      "INFO:root:Loaded cache in 6.835209 sec\n"
     ]
    }
   ],
   "source": [
    "dataset_splits = get_dataset_splits(dataset_name=metric_model.flags.dataset, data_dir=metric_model.flags.data_dir,\n",
    "                                    splits=[metric_model.flags.train_split, \n",
    "                                            metric_model.flags.test_split+\"_seen\", \n",
    "                                            metric_model.flags.test_split+\"_unseen\"], \n",
    "                                    flags=metric_model.flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing train embeddings\n",
      "221it [00:07, 27.71it/s]\n",
      "INFO:root:Computing test embeddings, unseen\n",
      "93it [00:02, 39.11it/s]\n",
      "INFO:root:Computing test embeddings, seen\n",
      "56it [00:01, 31.26it/s]\n",
      "INFO:root:Computing generalized zero-shot performance metrics\n",
      "INFO:root:Searching for '/mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/params.json'\n",
      "INFO:root:Loading existing params.\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.68it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  7.91it/s]\n",
      "INFO:root:Computing classical zero-shot performance metrics, test\n",
      "INFO:root:Searching for '/mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/params.json'\n",
      "INFO:root:Loading existing params.\n",
      "INFO:root:Computing classical zero-shot performance metrics, train\n",
      "INFO:root:Searching for '/mnt/scratch/boris/experiments_zeroshot_pairwise/190513_022122_txt2img_weight_dataset_text_feature_extractor_number_of_steps_repeat_modality_interaction_mi_weight_test_split_train_split_GZSL_results_test_split/mi_weight=0.5;repeat=0;txt2img_weight=0.5;test_split=test;train_split=trainval;dataset=xian2017_cub;text_feature_extractor=cnn_bi_lstm;number_of_steps=150001;modality_interaction=NONE/params.json'\n",
      "INFO:root:Loading existing params.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_AP@50/#sentences10': 0.27546666666666669,\n",
       " 'train_Top-1 Acc/#sentences10': 0.5038718115957046,\n",
       " 'train_AP@50/#sentences50': 0.33493333333333331,\n",
       " 'train_Top-1 Acc/#sentences50': 0.73742134804553949,\n",
       " 'train_AP@50/#sentences100': 0.35693333333333338,\n",
       " 'train_Top-1 Acc/#sentences100': 0.78107854798920373,\n",
       " 'train_AP@50/#sentences200': 0.35693333333333338,\n",
       " 'train_Top-1 Acc/#sentences200': 0.81136396747495765,\n",
       " 'train_AP@50/#sentences400': 0.35813333333333336,\n",
       " 'train_Top-1 Acc/#sentences400': 0.82568059673903593,\n",
       " 'train_AP@50/#sentences1000': 0.35880000000000006,\n",
       " 'train_Top-1 Acc/#sentences1000': 0.82647587532851052,\n",
       " 'test_AP@50/#sentences10': 0.32879999999999998,\n",
       " 'test_Top-1 Acc/#sentences10': 0.45823161541802082,\n",
       " 'test_AP@50/#sentences50': 0.36199999999999993,\n",
       " 'test_Top-1 Acc/#sentences50': 0.595602774027578,\n",
       " 'test_AP@50/#sentences100': 0.35920000000000002,\n",
       " 'test_Top-1 Acc/#sentences100': 0.65727380015049819,\n",
       " 'test_AP@50/#sentences200': 0.36920000000000008,\n",
       " 'test_Top-1 Acc/#sentences200': 0.65355476187850614,\n",
       " 'test_AP@50/#sentences400': 0.37280000000000002,\n",
       " 'test_Top-1 Acc/#sentences400': 0.67160337827796768,\n",
       " 'test_AP@50/#sentences1000': 0.37519999999999998,\n",
       " 'test_Top-1 Acc/#sentences1000': 0.67524725125673268,\n",
       " 'test_U_Top-1 Acc/#sentences10': 0.32628485414654818,\n",
       " 'test_S_Top-1 Acc/#sentences10': 0.31763120974885678,\n",
       " 'test_H_Top-1 Acc/#sentences10': 0.32189988340508913,\n",
       " 'test_U_Top-1 Acc/#sentences50': 0.49453306956782472,\n",
       " 'test_S_Top-1 Acc/#sentences50': 0.45566480850304381,\n",
       " 'test_H_Top-1 Acc/#sentences50': 0.47430397740003932,\n",
       " 'test_U_Top-1 Acc/#sentences100': 0.54917401623552065,\n",
       " 'test_S_Top-1 Acc/#sentences100': 0.49821693339340406,\n",
       " 'test_H_Top-1 Acc/#sentences100': 0.5224559069660395,\n",
       " 'test_U_Top-1 Acc/#sentences200': 0.57743265919007236,\n",
       " 'test_S_Top-1 Acc/#sentences200': 0.51092445735092795,\n",
       " 'test_H_Top-1 Acc/#sentences200': 0.54214643993146894,\n",
       " 'test_U_Top-1 Acc/#sentences400': 0.59886242735683648,\n",
       " 'test_S_Top-1 Acc/#sentences400': 0.5231765451324274,\n",
       " 'test_H_Top-1 Acc/#sentences400': 0.55846683303536837,\n",
       " 'test_U_Top-1 Acc/#sentences1000': 0.60492578490324489,\n",
       " 'test_S_Top-1 Acc/#sentences1000': 0.5279004007974597,\n",
       " 'test_H_Top-1 Acc/#sentences1000': 0.5637944608521106}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_eval, embeddings = feature_model.eval_acc_gzsh(train_loader=dataset_splits[metric_model.flags.train_split], \n",
    "                                                       test_loader_seen=dataset_splits[metric_model.flags.test_split+\"_seen\"],\n",
    "                                                       test_loader_unseen=dataset_splits[metric_model.flags.test_split+\"_unseen\"],\n",
    "                                                       batch_size=32, seen_adjustment=0.02) # 0.015\n",
    "results_eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reimplement the evaluation framework and verify it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:04, 13.11it/s]\n",
      "18it [00:01, 13.21it/s]\n",
      "30it [00:02, 12.28it/s]\n"
     ]
    }
   ],
   "source": [
    "image_embeddings_train, text_embeddings_train = feature_model.predict_all(dataset_splits[\"trainval\"], batch_size=100)\n",
    "\n",
    "image_embeddings_seen, text_embeddings_seen = feature_model.predict_all(dataset_splits[\"test_seen\"], batch_size=100)\n",
    "\n",
    "image_embeddings_unseen, text_embeddings_unseen = feature_model.predict_all(dataset_splits[\"test_unseen\"], batch_size=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute class prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.array(dataset_splits[\"trainval\"].image_classes)\n",
    "labels_seen = np.array(dataset_splits[\"test_seen\"].image_classes)\n",
    "labels_unseen = np.array(dataset_splits[\"test_unseen\"].image_classes)\n",
    "labels_all = np.concatenate([labels_train, labels_seen, labels_unseen])\n",
    "\n",
    "classes_seen = np.array(list(set(labels_train)))\n",
    "classes_unseen = np.array(list(set(labels_unseen)))\n",
    "\n",
    "text_embeddings_all = np.concatenate([text_embeddings_train, text_embeddings_seen, text_embeddings_unseen])\n",
    "seen_unseen_labels_indicator = np.isin(np.array(labels_all), classes_seen)\n",
    "\n",
    "\n",
    "def get_prototypes(embeddings, labels):\n",
    "    class_labels = list(set(labels))\n",
    "    labels = np.array(labels)\n",
    "    prototypes = dict()\n",
    "    for c in class_labels:\n",
    "        prototypes[c] = embeddings[labels == c].mean(axis=0)\n",
    "    return prototypes\n",
    "    \n",
    "    \n",
    "prototypes_dict = get_prototypes(embeddings=text_embeddings_all, labels=labels_all)\n",
    "\n",
    "prototypes = np.array(list(prototypes_dict.values()))\n",
    "prototypes_classes = np.array(list(prototypes_dict.keys()))\n",
    "seen_unseen_prototypes = np.isin(prototypes_classes, classes_seen)\n",
    "\n",
    "assert len(labels_all) == len(labels_train) + len(labels_seen) + len(labels_unseen)\n",
    "# assert len(prototypes_dict) == 200\n",
    "assert len(prototypes_dict['001']) == 1024\n",
    "assert sum(seen_unseen_labels_indicator) == len(labels_train) + len(labels_seen)\n",
    "assert sum(~seen_unseen_labels_indicator) == len(labels_unseen)\n",
    "assert sum(seen_unseen_prototypes) == len(classes_seen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Top-1 accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random permutation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0056854557057210812"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top1_acc(labels, predictions):\n",
    "    class_labels = list(set(labels))\n",
    "    match_count = dict()\n",
    "    total_count = dict()\n",
    "    acc_by_class = dict()\n",
    "    for c in class_labels:\n",
    "        entries_of_class_c = labels == c\n",
    "        total_count[c] = sum(entries_of_class_c)\n",
    "        match_count[c] = sum(labels[entries_of_class_c] == predictions[entries_of_class_c])\n",
    "        acc_by_class[c] = match_count[c] / total_count[c]\n",
    "    \n",
    "    return np.array(list(acc_by_class.values())).mean()\n",
    "    \n",
    "assert top1_acc(labels=labels_all, predictions=labels_all) == 1.0\n",
    "\n",
    "print(\"Accuracy of random permutation\")\n",
    "top1_acc(labels=labels_all, predictions=np.random.choice(labels_all, size=len(labels_all), replace=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement nearest prototype classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_prototype_classify(prototypes_dict, seen_unseen_prototypes, query_embeddings, alpha):\n",
    "    prototypes = np.array(list(prototypes_dict.values()))\n",
    "    prototypes_classes = np.array(list(prototypes_dict.keys()))\n",
    "    \n",
    "    dist = np.sqrt(np.square(prototypes[:,:,None] - query_embeddings.transpose()).sum(axis=-2))\n",
    "    dist = dist * (1.0 + alpha*seen_unseen_prototypes[:,None])\n",
    "    \n",
    "    return prototypes_classes[np.argmin(dist, axis=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_seen = nearest_prototype_classify(prototypes_dict = prototypes_dict, \n",
    "                                               seen_unseen_prototypes = seen_unseen_prototypes, \n",
    "                                               query_embeddings = image_embeddings_seen, \n",
    "                                               alpha = alpha)\n",
    "predictions_unseen = nearest_prototype_classify(prototypes_dict = prototypes_dict, \n",
    "                                               seen_unseen_prototypes = seen_unseen_prototypes, \n",
    "                                               query_embeddings = image_embeddings_unseen, \n",
    "                                               alpha = alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = top1_acc(labels=labels_seen, predictions=predictions_seen)\n",
    "u = top1_acc(labels=labels_unseen, predictions=predictions_unseen)\n",
    "H = 2*s*u / (s+u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy seen: 0.527900400797\n",
      "Accuracy unseen: 0.604925784903\n",
      "Accuracy harmonic mean: 0.563794460852\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy seen:\", s)\n",
    "print(\"Accuracy unseen:\", u)\n",
    "print(\"Accuracy harmonic mean:\", H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
